import { useState, useEffect, useCallback, useRef } from 'react';

// Types pour Web Speech API
interface SpeechRecognitionEvent extends Event {
  results: SpeechRecognitionResultList;
  resultIndex: number;
}

interface SpeechRecognition extends EventTarget {
  continuous: boolean;
  interimResults: boolean;
  lang: string;
  start(): void;
  stop(): void;
  abort(): void;
  onstart: ((this: SpeechRecognition, ev: Event) => any) | null;
  onend: ((this: SpeechRecognition, ev: Event) => any) | null;
  onresult: ((this: SpeechRecognition, ev: SpeechRecognitionEvent) => any) | null;
  onerror: ((this: SpeechRecognition, ev: Event) => any) | null;
}

declare global {
  interface Window {
    SpeechRecognition: new () => SpeechRecognition;
    webkitSpeechRecognition: new () => SpeechRecognition;
  }
}

export type SpeechState = 'idle' | 'listening' | 'thinking' | 'speaking' | 'error';

export interface UseSpeechReturn {
  // √âtat
  state: SpeechState;
  isSupported: boolean;
  transcript: string;
  error: string | null;
  isListening: boolean;
  isSpeaking: boolean;
  
  // Actions
  startListening: () => void;
  stopListening: () => void;
  speak: (text: string) => Promise<void>;
  stopSpeaking: () => void;
  clearTranscript: () => void;
  
  // Configuration
  setLanguage: (lang: string) => void;
  setVoice: (voice: SpeechSynthesisVoice | null) => void;
  
  // Informations
  availableVoices: SpeechSynthesisVoice[];
  currentVoice: SpeechSynthesisVoice | null;
}

/**
 * Hook pour g√©rer la Web Speech API (STT + TTS)
 */
export function useSpeech(): UseSpeechReturn {
  // √âtats
  const [state, setState] = useState<SpeechState>('idle');
  const [transcript, setTranscript] = useState('');
  const [error, setError] = useState<string | null>(null);
  const [availableVoices, setAvailableVoices] = useState<SpeechSynthesisVoice[]>([]);
  const [currentVoice, setCurrentVoice] = useState<SpeechSynthesisVoice | null>(null);
  const [language, setLanguage] = useState('fr-FR');
  
  // Refs
  const recognitionRef = useRef<SpeechRecognition | null>(null);
  const utteranceRef = useRef<SpeechSynthesisUtterance | null>(null);
  const isListeningRef = useRef(false);
  
  // V√©rification du support
  const isSupported = Boolean(
    typeof window !== 'undefined' &&
    (window.SpeechRecognition || window.webkitSpeechRecognition) &&
    window.speechSynthesis
  );

  /**
   * Initialise la reconnaissance vocale
   */
  const initializeRecognition = useCallback(() => {
    if (!isSupported) return null;

    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    const recognition = new SpeechRecognition();
    
    recognition.continuous = false;
    recognition.interimResults = true;
    recognition.lang = language;
    
    recognition.onstart = () => {
      setState('listening');
      setError(null);
      isListeningRef.current = true;
    };
    
    recognition.onend = () => {
      setState('idle');
      isListeningRef.current = false;
    };
    
    recognition.onresult = (event: SpeechRecognitionEvent) => {
      let finalTranscript = '';
      let interimTranscript = '';
      
      for (let i = event.resultIndex; i < event.results.length; i++) {
        const result = event.results[i];
        if (result.isFinal) {
          finalTranscript += result[0].transcript;
        } else {
          interimTranscript += result[0].transcript;
        }
      }
      
      if (finalTranscript) {
        setTranscript(finalTranscript.trim());
        setState('idle');
      } else {
        setTranscript(interimTranscript.trim());
      }
    };
    
    recognition.onerror = (event: any) => {
      console.error('Erreur reconnaissance vocale:', event.error);
      
      let errorMessage = 'Erreur de reconnaissance vocale';
      switch (event.error) {
        case 'not-allowed':
          errorMessage = 'Microphone non autoris√©. Veuillez autoriser l\'acc√®s au microphone.';
          break;
        case 'no-speech':
          errorMessage = 'Aucune parole d√©tect√©e. R√©essayez en parlant plus fort.';
          break;
        case 'audio-capture':
          errorMessage = 'Microphone non disponible.';
          break;
        case 'network':
          errorMessage = 'Erreur r√©seau pour la reconnaissance vocale.';
          break;
      }
      
      setError(errorMessage);
      setState('error');
      isListeningRef.current = false;
    };
    
    return recognition;
  }, [isSupported, language]);

  /**
   * Charge les voix disponibles
   */
  const loadVoices = useCallback(() => {
    if (!isSupported) return;
    
    const voices = speechSynthesis.getVoices();
    setAvailableVoices(voices);
    
    // S√©lectionne la meilleure voix fran√ßaise disponible
    // Priorit√© : Google Premium > Microsoft Neural > Autres
    const frenchVoice = 
      // 1. Voix Google Premium (tr√®s naturelles)
      voices.find(voice => 
        voice.lang.startsWith('fr') && 
        (voice.name.includes('Google') || voice.name.includes('premium')) &&
        (voice.name.includes('Female') || voice.name.includes('Am√©lie') || voice.name.includes('Clara'))
      ) ||
      // 2. Voix Microsoft Neural (qualit√© √©lev√©e)
      voices.find(voice => 
        voice.lang.startsWith('fr') && 
        voice.name.includes('Microsoft') &&
        (voice.name.includes('Denise') || voice.name.includes('Neural'))
      ) ||
      // 3. Voix Apple (bonne qualit√© sur Safari/Mac)
      voices.find(voice => 
        voice.lang.startsWith('fr') && 
        (voice.name.includes('Am√©lie') || voice.name.includes('Thomas'))
      ) ||
      // 4. N'importe quelle voix fran√ßaise f√©minine
      voices.find(voice => 
        voice.lang.startsWith('fr') && 
        (voice.name.includes('Female') || voice.name.includes('femme'))
      ) ||
      // 5. Fallback : premi√®re voix fran√ßaise
      voices.find(voice => voice.lang.startsWith('fr'));
    
    if (frenchVoice && !currentVoice) {
      setCurrentVoice(frenchVoice);
      console.log('üé§ Voix s√©lectionn√©e:', frenchVoice.name, '-', frenchVoice.lang);
    }
  }, [isSupported, currentVoice]);

  /**
   * D√©marre l'√©coute
   */
  const startListening = useCallback(() => {
    if (!isSupported || isListeningRef.current) return;
    
    try {
      if (!recognitionRef.current) {
        recognitionRef.current = initializeRecognition();
      }
      
      if (recognitionRef.current) {
        setTranscript('');
        setError(null);
        recognitionRef.current.start();
      }
    } catch (error) {
      console.error('Erreur d√©marrage reconnaissance:', error);
      setError('Impossible de d√©marrer la reconnaissance vocale');
      setState('error');
    }
  }, [isSupported, initializeRecognition]);

  /**
   * Arr√™te l'√©coute
   */
  const stopListening = useCallback(() => {
    if (recognitionRef.current && isListeningRef.current) {
      recognitionRef.current.stop();
    }
  }, []);

  /**
   * Synth√®se vocale
   */
  const speak = useCallback(async (text: string): Promise<void> => {
    if (!isSupported || !text.trim()) return;
    
    return new Promise((resolve, reject) => {
      try {
        // Arr√™te toute synth√®se en cours
        speechSynthesis.cancel();
        
        const utterance = new SpeechSynthesisUtterance(text);
        utteranceRef.current = utterance;
        
        // Configuration de la voix
        if (currentVoice) {
          utterance.voice = currentVoice;
        }
        utterance.lang = language;
        
        // Param√®tres optimis√©s pour une voix plus naturelle
        utterance.rate = 0.95;  // L√©g√®rement ralenti pour plus de clart√©
        utterance.pitch = 1.05; // L√©g√®rement plus aigu pour un ton plus agr√©able
        utterance.volume = 0.9; // Volume un peu plus fort
        
        utterance.onstart = () => {
          setState('speaking');
        };
        
        utterance.onend = () => {
          setState('idle');
          resolve();
        };
        
        utterance.onerror = (event) => {
          console.error('Erreur synth√®se vocale:', event);
          setState('error');
          setError('Erreur de synth√®se vocale');
          reject(new Error('Erreur synth√®se vocale'));
        };
        
        speechSynthesis.speak(utterance);
        
      } catch (error) {
        console.error('Erreur speak:', error);
        setState('error');
        setError('Impossible de lire le texte');
        reject(error);
      }
    });
  }, [isSupported, currentVoice, language]);

  /**
   * Arr√™te la synth√®se vocale
   */
  const stopSpeaking = useCallback(() => {
    if (speechSynthesis.speaking) {
      speechSynthesis.cancel();
      setState('idle');
    }
  }, []);

  /**
   * Efface le transcript
   */
  const clearTranscript = useCallback(() => {
    setTranscript('');
    setError(null);
  }, []);

  /**
   * Change la voix
   */
  const setVoice = useCallback((voice: SpeechSynthesisVoice | null) => {
    setCurrentVoice(voice);
  }, []);

  // Effets
  useEffect(() => {
    if (isSupported) {
      loadVoices();
      
      // √âcoute les changements de voix (certains navigateurs chargent les voix de fa√ßon asynchrone)
      speechSynthesis.onvoiceschanged = loadVoices;
      
      return () => {
        speechSynthesis.onvoiceschanged = null;
      };
    }
  }, [isSupported, loadVoices]);

  // Nettoyage au d√©montage
  useEffect(() => {
    return () => {
      if (recognitionRef.current && isListeningRef.current) {
        recognitionRef.current.abort();
      }
      if (speechSynthesis.speaking) {
        speechSynthesis.cancel();
      }
    };
  }, []);

  return {
    // √âtat
    state,
    isSupported,
    transcript,
    error,
    isListening: state === 'listening',
    isSpeaking: state === 'speaking',
    
    // Actions
    startListening,
    stopListening,
    speak,
    stopSpeaking,
    clearTranscript,
    
    // Configuration
    setLanguage,
    setVoice,
    
    // Informations
    availableVoices,
    currentVoice,
  };
}