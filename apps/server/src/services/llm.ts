import { z } from 'zod';
import type { DocChunk, Citation, LLMResponse } from '../rag/types.js';
import { LLMResponseSchema } from '../rag/types.js';
import { env } from '../config/env.js';
import { isGeminiAvailable } from '../services/gemini.js';

// ==========================================
// SERVICE LLM - GEMINI + FALLBACK LOCAL
// ==========================================

/**
 * Prompt syst√®me pour l'assistant Sofinco avec RAG - Version conversationnelle
 */
const RAG_SYSTEM_PROMPT = `Tu es l'Assistant Cr√©dit Sofinco, un conseiller virtuel sp√©cialis√© qui privil√©gie une conversation naturelle.

R√îLE:
- Aide les clients avec leurs questions sur les cr√©dits Sofinco
- Maintiens une conversation fluide et personnalis√©e
- Utilise UNIQUEMENT les informations fournies dans le contexte
- Adapte tes r√©ponses selon l'historique de conversation

STYLE CONVERSATIONNEL:
1. Utilise le vouvoiement mais de mani√®re chaleureuse
2. Reconnais les √©l√©ments d√©j√† discut√©s ("Comme nous avons vu...", "Pour revenir √†...")
3. Pose des questions de clarification naturelles
4. Utilise des transitions fluides entre les sujets
5. Exprime de l'empathie pour les besoins du client ("Je comprends que...", "C'est tout √† fait normal de...")
6. Maximum 150 mots, mais privil√©gie la clart√©

GESTION DU CONTEXTE:
- Si c'est le d√©but de conversation : sois accueillant
- Si la conversation continue : r√©f√©rence les √©l√©ments pr√©c√©dents
- Si le client change de sujet : fais une transition naturelle
- Si le client semble confus : reformule avec bienveillance

INTERDICTIONS:
- Pas de formules robotiques ou r√©p√©titives
- Pas de sur-politesse excessive
- Pas d'invention - uniquement le contexte fourni
- Pas de mention "prototype", "d√©mo", "informations non contractuelles"

IMPORTANT: Cr√©√© une v√©ritable relation conseiller-client, comme dans une agence physique.`;

/**
 * Sch√©ma pour valider la r√©ponse de Gemini
 */
const GeminiResponseSchema = z.object({
  reply: z.string(),
  citations: z.array(z.object({
    title: z.string(),
    anchor: z.string().optional(),
  })),
  confidence: z.number().min(0).max(1).optional(),
});

/**
 * D√©tecte l'intention de la requ√™te utilisateur
 */
export function detectIntention(query: string): 'simulation' | 'faq' | 'other' {
  const lowerQuery = query.toLowerCase();
  
  // Mots-cl√©s pour questions FAQ (prioritaires)
  const faqKeywords = [
    'comment', 'pourquoi', 'qu\'est-ce', 'quelle', 'quel', 'quels', 'quelles',
    'qui peut', 'conditions', 'documents', 'justificatifs', 'd√©lai', 'd√©lais',
    'proc√©dure', '√©tapes', 'comment faire', 'c\'est quoi', 'diff√©rence',
    'avantages', 'inconv√©nients', '√©ligible', '√©ligibilit√©', 'autoris√©'
  ];
  
  // V√©rifier d'abord les questions FAQ
  const hasFaqKeywords = faqKeywords.some(keyword => 
    lowerQuery.includes(keyword)
  );
  
  if (hasFaqKeywords) {
    return 'faq';
  }
  
  // Mots-cl√©s pour simulation (actions concr√®tes)
  const simulationKeywords = [
    'simuler', 'simulation', 'mensualit√©', 'calculer',
    'emprunter', 'financer', 'je veux', 'je voudrais',
    'j\'ai besoin', 'besoin de'
  ];
  
  // V√©rifier si la requ√™te contient des mots-cl√©s de simulation
  const hasSimulationKeywords = simulationKeywords.some(keyword => 
    lowerQuery.includes(keyword)
  );
  
  // V√©rifier si la requ√™te contient des chiffres (montant ou dur√©e)
  const hasNumbers = /\d+/.test(query);
  
  // Si mots-cl√©s de simulation + chiffres = simulation claire
  if (hasSimulationKeywords && hasNumbers) {
    return 'simulation';
  }
  
  // Si juste des mots-cl√©s de simulation sans chiffres
  if (hasSimulationKeywords) {
    return 'simulation';
  }
  
  // Par d√©faut, consid√©rer comme FAQ
  return 'faq';
}

/**
 * Extrait les param√®tres de simulation d'une requ√™te
 */
export function extractSimulationParams(query: string): {
  amount?: number;
  duration?: number;
  hasParams: boolean;
} {
  const result = { hasParams: false };
  
  // Rechercher un montant en euros
  const amountMatch = query.match(/(\d+(?:\s*\d{3})*)\s*‚Ç¨?/);
  if (amountMatch && amountMatch[1]) {
    const amount = parseInt(amountMatch[1].replace(/\s/g, ''));
    if (amount >= 1000 && amount <= 75000) {
      (result as any).amount = amount;
      result.hasParams = true;
    }
  }
  
  // Rechercher une dur√©e en mois
  const durationMatch = query.match(/(\d+)\s*mois/);
  if (durationMatch && durationMatch[1]) {
    const duration = parseInt(durationMatch[1]);
    if (duration >= 6 && duration <= 84) {
      (result as any).duration = duration;
      result.hasParams = true;
    }
  }
  
  return result;
}

/**
 * G√©n√®re des citations √† partir des chunks
 */
function generateCitationsFromChunks(chunks: DocChunk[]): Citation[] {
  const citationMap = new Map<string, Citation>();
  
  chunks.forEach(chunk => {
    // Utiliser le titre du document comme cl√© unique
    const key = chunk.title;
    
    if (!citationMap.has(key)) {
      citationMap.set(key, {
        title: chunk.title,
        url: chunk.url,
        anchor: chunk.url?.includes('#') ? chunk.url.split('#')[1] : undefined,
      });
    }
  });
  
  return Array.from(citationMap.values());
}

/**
 * R√©ponse avec Gemini (mode LIVE) - Version conversationnelle
 */
export async function answerWithGemini(
  query: string, 
  retrievedChunks: DocChunk[],
  conversationHistory?: Array<{role: string, message: string}>
): Promise<LLMResponse> {
  try {
    if (!isGeminiAvailable()) {
      throw new Error('Gemini non disponible');
    }
    
    // Pr√©parer le contexte √† partir des chunks
    const context = retrievedChunks.map((chunk, index) => 
      `[Source ${index + 1}: ${chunk.title}]\n${chunk.text}`
    ).join('\n\n');
    
    // Construire l'historique de conversation pour le contexte
    const historyContext = conversationHistory && conversationHistory.length > 0 
      ? `\n\nHISTORIQUE DE CONVERSATION R√âCENTE:\n${conversationHistory
          .slice(-4) // Garder seulement les 4 derniers √©changes
          .map(h => `${h.role.toUpperCase()}: ${h.message}`)
          .join('\n')}\n`
      : '';
    
    // Construire le prompt avec contexte
    const prompt = `${RAG_SYSTEM_PROMPT}

CONTEXTE FOURNI:
${context}${historyContext}

QUESTION CLIENT ACTUELLE: ${query}

R√âPONSE (format JSON attendu):
{
  "reply": "Votre r√©ponse conversationnelle en utilisant le vouvoiement",
  "citations": [{"title": "Titre de la source", "anchor": "section-si-applicable"}],
  "confidence": 0.8
}`;

    // Pour l'instant, on simule la r√©ponse Gemini en mode LIVE
    // TODO: Impl√©menter l'int√©gration Gemini compl√®te
    console.log('ü§ñ Simulation r√©ponse Gemini avec contexte:', context.substring(0, 200) + '...');
    
    // R√©ponse simul√©e bas√©e sur le contexte - Plus conversationnelle
    const contextSummary = retrievedChunks.slice(0, 2).map(chunk => 
      chunk.text.split('.')[0] + '.'
    ).join(' ');
    
    const simulatedReply = contextSummary;
    
    return {
      reply: simulatedReply,
      citations: generateCitationsFromChunks(retrievedChunks),
      confidence: 0.8,
    };
    
  } catch (error) {
    console.error('‚ùå Erreur Gemini:', error);
    
    // Fallback vers la r√©ponse locale
    return answerLocally(query, retrievedChunks, conversationHistory);
  }
}

/**
 * Phrases d'introduction conversationnelles (adapt√©es au contexte)
 */
const CONVERSATIONAL_INTROS = [
  '',  // R√©ponse directe
  'Bien s√ªr, ',
  'Absolument, ',
  'Je comprends votre question. ',
  'C\'est une excellente question. ',
  'Laissez-moi vous expliquer cela. ',
  'D\'accord, ',
  'Tr√®s bonne question. ',
];

/**
 * Phrases d'introduction pour continuation de conversation
 */
const CONTINUATION_INTROS = [
  'Pour revenir √† votre projet, ',
  'Comme nous avons vu, ',
  'En compl√©ment de ce que nous avons discut√©, ',
  'Pour pr√©ciser davantage, ',
  'Dans votre situation, ',
];

/**
 * Phrases empathiques pour humaniser les r√©ponses
 */
const EMPATHETIC_PHRASES = [
  'Je comprends que ce soit important pour vous. ',
  'C\'est tout √† fait normal de se poser cette question. ',
  'Votre pr√©occupation est l√©gitime. ',
  'Je vois que vous souhaitez bien vous informer. ',
  'C\'est une d√©marche tr√®s r√©fl√©chie de votre part. ',
];

/**
 * Suggestions contextuelles pour terminer naturellement - Version enrichie
 */
const CONTEXTUAL_SUGGESTIONS: Record<string, string[]> = {
  'conditions': [
    ' Si vous le souhaitez, je peux vous expliquer la proc√©dure de demande en d√©tail.',
    ' Je peux √©galement vous aider √† estimer votre capacit√© d\'emprunt.',
    ' Voulez-vous en savoir plus sur les documents n√©cessaires ?',
    ' N\'h√©sitez pas √† me dire quels points vous pr√©occupent le plus.'
  ],
  'documents': [
    ' Je peux aussi vous expliquer comment pr√©parer votre dossier.',
    ' Souhaitez-vous conna√Ætre les d√©lais de traitement habituels ?',
    ' Je reste disponible pour toute pr√©cision sur la proc√©dure.',
    ' Si certains documents vous posent probl√®me, dites-le moi.'
  ],
  'taux': [
    ' Je peux vous aider √† simuler votre cr√©dit pour voir les mensualit√©s.',
    ' Voulez-vous conna√Ætre les diff√©rentes options de remboursement ?',
    ' N\'h√©sitez pas si vous avez d\'autres questions sur le financement.',
    ' Souhaitez-vous que je vous explique ce qui influence le taux ?'
  ],
  'montant': [
    ' Je peux √©galement vous expliquer comment sont calcul√©es les mensualit√©s.',
    ' Souhaitez-vous en savoir plus sur les conditions d\'√©ligibilit√© ?',
    ' Je reste √† votre disposition pour affiner votre projet.',
    ' Voulez-vous que nous regardions ensemble les options possibles ?'
  ],
  'd√©lai': [
    ' Je peux vous guider dans la constitution de votre dossier si besoin.',
    ' Voulez-vous conna√Ætre les √©tapes d√©taill√©es de la demande ?',
    ' N\'h√©sitez pas pour toute autre question.',
    ' Y a-t-il un calendrier particulier qui vous pr√©occupe ?'
  ],
  'simulation': [
    ' Voulez-vous que nous lancions une simulation ensemble ?',
    ' Je peux vous expliquer les diff√©rents param√®tres √† consid√©rer.',
    ' Avez-vous d√©j√† une id√©e du montant souhait√© ?',
    ' Quel type de projet souhaitez-vous financer ?'
  ],
  'default': [
    ' Je reste √† votre disposition pour toute autre question.',
    ' N\'h√©sitez pas si vous avez besoin de pr√©cisions.',
    ' Je peux vous en dire plus si vous le souhaitez.',
    ' Y a-t-il autre chose qui vous int√©resse ?'
  ]
};

/**
 * S√©lectionne une introduction adapt√©e au contexte de conversation
 */
function getConversationalIntro(query: string, isFirstMessage: boolean = true): string {
  if (!isFirstMessage) {
    // Pour les messages de continuation, utiliser des intros contextuelles
    const continuationIntros = CONTINUATION_INTROS;
    if (Math.random() < 0.3) { // 30% de chance d'utiliser une intro de continuation
      return continuationIntros[Math.floor(Math.random() * continuationIntros.length)] || '';
    }
  }
  
  // Utiliser des intros empathiques pour certains types de questions
  const lowerQuery = query.toLowerCase();
  const hasUncertainty = lowerQuery.includes('je ne sais pas') || lowerQuery.includes('pas s√ªr') || 
                        lowerQuery.includes('h√©siter') || lowerQuery.includes('comprends pas');
  
  if (hasUncertainty && Math.random() < 0.4) {
    return EMPATHETIC_PHRASES[Math.floor(Math.random() * EMPATHETIC_PHRASES.length)] || '';
  }
  
  // Intros conversationnelles standard
  return CONVERSATIONAL_INTROS[Math.floor(Math.random() * CONVERSATIONAL_INTROS.length)] || '';
}
/**
 * S√©lectionne une suggestion contextuelle bas√©e sur la requ√™te
 */
function getContextualSuggestion(query: string): string {
  const lowerQuery = query.toLowerCase();
  
  // Chercher le contexte le plus pertinent
  for (const [key, suggestions] of Object.entries(CONTEXTUAL_SUGGESTIONS)) {
    if (key !== 'default' && lowerQuery.includes(key)) {
      const suggestion = suggestions[Math.floor(Math.random() * suggestions.length)];
      return suggestion || '';
    }
  }
  
  // Fallback : suggestion par d√©faut
  const defaultSuggestions = CONTEXTUAL_SUGGESTIONS['default'];
  if (defaultSuggestions) {
    return defaultSuggestions[Math.floor(Math.random() * defaultSuggestions.length)] || '';
  }
  
  return '';
}

/**
 * R√©ponse locale extractive (mode MOCK) - Version conversationnelle
 */
export function answerLocally(
  query: string, 
  retrievedChunks: DocChunk[],
  conversationHistory?: Array<{role: string, message: string}>
): LLMResponse {
  try {
    if (retrievedChunks.length === 0) {
      return {
        reply: 'Je n\'ai pas l\'information pr√©cise pour r√©pondre √† cette question. Je vous invite √† contacter directement un conseiller au 0 800 767 000.',
        citations: [],
        confidence: 0.1,
      };
    }
    
    // Analyser l'historique pour d√©tecter les patterns de conversation
    const isFirstMessage = !conversationHistory || conversationHistory.length === 0;
    const lastUserMessages = conversationHistory?.filter(h => h.role === 'user').slice(-2) || [];
    const firstQueryWord = query.toLowerCase().split(' ')[0] || '';
    const hasAskedSimilarBefore = lastUserMessages.some(msg => 
      firstQueryWord && msg.message.toLowerCase().includes(firstQueryWord)
    );
    
    // Extraire les mots-cl√©s de la requ√™te
    const queryKeywords = query
      .toLowerCase()
      .replace(/[^\w\s]/g, ' ')
      .split(/\s+/)
      .filter(word => word.length > 3);
    
    // Scorer les chunks par pertinence
    const scoredChunks = retrievedChunks.map(chunk => {
      const text = chunk.text.toLowerCase();
      const score = queryKeywords.reduce((acc, keyword) => {
        const count = (text.match(new RegExp(keyword, 'g')) || []).length;
        return acc + count;
      }, 0);
      
      return { chunk, score };
    });
    
    // Trier par score et prendre les meilleurs
    scoredChunks.sort((a, b) => b.score - a.score);
    const bestChunks = scoredChunks.slice(0, 3);
    
    // Intro conversationnelle adapt√©e
    let intro = getConversationalIntro(query, isFirstMessage);
    
    // Adapter l'intro si question similaire d√©j√† pos√©e
    if (hasAskedSimilarBefore) {
      intro = 'Pour compl√©ter ce que nous avons vu, ';
    }
    
    let reply: string = intro;
    
    // Construire une r√©ponse naturelle
    const contentParts: string[] = [];
    
    bestChunks.forEach((item) => {
      if (item.score > 0) {
        // Extraire les phrases les plus pertinentes
        const sentences = item.chunk.text.split(/[.!?]+/);
        const relevantSentences = sentences
          .filter(sentence => {
            const lower = sentence.toLowerCase();
            return queryKeywords.some(keyword => lower.includes(keyword));
          })
          .map(s => s.trim())
          .filter(s => s.length > 10)
          .slice(0, 2);
        
        if (relevantSentences.length > 0) {
          contentParts.push(relevantSentences.join('. '));
        }
      }
    });
    
        if (contentParts.length > 0) {
          // Joindre les parties avec des connecteurs naturels
          reply += contentParts.join('. ') + '.';
          
          // Nettoyer les r√©p√©titions et les artefacts
          reply = reply
            .replace(/\s+/g, ' ')  // Espaces multiples
            .replace(/\.+/g, '.')  // Points multiples
            .replace(/\.\s*\./g, '.') // Point point
            .trim();
          
          // Ajouter des √©l√©ments conversationnels selon le contexte
          if (conversationHistory && conversationHistory.length > 2) {
            // Conversation avanc√©e - r√©f√©rences subtiles au pass√©
            if (Math.random() < 0.2) {
              const contextualPhrases = [
                'Comme nous en parlions, ',
                'Pour compl√©ter ce que je vous disais, ',
                'Dans la continuit√© de notre √©change, '
              ];
              const randomPhrase = contextualPhrases[Math.floor(Math.random() * contextualPhrases.length)];
              if (randomPhrase) {
                reply = randomPhrase + reply.charAt(0).toLowerCase() + reply.slice(1);
              }
            }
          }
          
          // Ajouter une suggestion contextuelle naturelle
          const suggestion = getContextualSuggestion(query);
          if (suggestion) {
            reply += suggestion;
          }
          
        } else {
          reply += 'Les informations disponibles ne correspondent pas exactement √† votre question.';
          
          // Ajouter de l'empathie pour les cas sans r√©ponse
          if (hasAskedSimilarBefore) {
            reply += ' Je vois que cette question vous pr√©occupe vraiment.';
          }
          
          reply += ' Un conseiller pourra vous apporter une r√©ponse plus pr√©cise.';
        }    // Pas de mention "prototype" - le prospect sait que c'est une d√©mo
    
    return {
      reply,
      citations: generateCitationsFromChunks(retrievedChunks),
      confidence: Math.min(bestChunks[0]?.score || 0, 10) / 10,
    };
    
  } catch (error) {
    console.error('‚ùå Erreur r√©ponse locale:', error);
    
    return {
      reply: 'Je rencontre une difficult√© technique. Veuillez contacter un conseiller au 0 800 767 000.',
      citations: [],
      confidence: 0.1,
    };
  }
}

/**
 * Point d'entr√©e principal pour g√©n√©rer une r√©ponse conversationnelle
 */
export async function generateAnswer(
  query: string, 
  retrievedChunks: DocChunk[],
  conversationHistory?: Array<{role: string, message: string}>
): Promise<LLMResponse> {
  console.log(`üß† G√©n√©ration de r√©ponse conversationnelle pour: "${query}" avec ${retrievedChunks.length} chunks`);
  
  try {
    let response: LLMResponse;
    
    if (env.USE_MOCK) {
      console.log('üé≠ Mode MOCK - Utilisation r√©ponse locale conversationnelle');
      response = answerLocally(query, retrievedChunks, conversationHistory);
    } else {
      console.log('ü§ñ Mode LIVE - Tentative Gemini conversationnelle');
      response = await answerWithGemini(query, retrievedChunks, conversationHistory);
    }
    
    // Valider la r√©ponse
    const validatedResponse = LLMResponseSchema.parse(response);
    
    console.log(`‚úÖ R√©ponse g√©n√©r√©e (${validatedResponse.citations.length} citations)`);
    return validatedResponse;
    
  } catch (error) {
    console.error('‚ùå Erreur g√©n√©ration r√©ponse:', error);
    
    // R√©ponse d'erreur de fallback
    return {
      reply: 'Je rencontre une difficult√© technique. Veuillez r√©essayer ou contacter un conseiller Sofinco au 0 800 767 000.',
      citations: [],
      confidence: 0.1,
    };
  }
}

/**
 * Optimise la requ√™te pour la recherche RAG
 */
export function optimizeQueryForRAG(query: string): string {
  return query
    // Supprimer les mots vides fr√©quents
    .replace(/\b(je|tu|il|elle|nous|vous|ils|elles|le|la|les|un|une|des|du|de|et|ou|mais|donc|or|ni|car)\b/gi, ' ')
    // Normaliser les espaces
    .replace(/\s+/g, ' ')
    .trim();
}